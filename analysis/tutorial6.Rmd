---
title: "Tutorial 6 - Machine Learning"
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: true
---


# Machine Learning in R

The question: If you enter hospital with a PD of Pneumonia, what factors determine if you will survive?


## Load Libraries
We will use a library called `healthcareai`, which is a conglomeration of many other machine learning libraries, mashed together in one beautiful package. 


```{r,warning=FALSE,message=FALSE,echo=TRUE}

# load libraries
library(knitr)
opts_chunk$set(warning=F,message=F,fig.width = 11,fig.height = 5,cache=F, echo=T)
library(tidyverse)
library("RPostgreSQL")

library(healthcareai)

```
## Get data from SQL

```{r database_setup, echo=TRUE, warnings=FALSE, messages=FALSE}

# create connection to the database
con <- dbConnect(dbDriver("PostgreSQL"), 
				 dbname   = 'vaed_full',
				 host = "himsql7.latrobe.edu.au", port = 5432,
				 user = "dewollershei-test", password = "healthGuru")
#
# this is the query to get all tne pneumonia diagnois.  the 3 commented lines would also finn the principal procedure
query_diag <- " 
select ad.position, diag_code, admission_id, age_years, los, 
sameday_id, drg, sex_desc, diag_short_desc, sep_mode_desc, care_type_desc,
sep_mode_id
---, procedure_short_desc
from admission JOIN sex using (sex_id)
join admission_diagnosis ad using (admission_id)
join diagnosis_desc using (diag_code)
join admission_procedure ap USING (admission_id) 
---join procedure_desc using (procedure_code)
JOIN separation_mode USING (sep_mode_id)
JOIN care_type USING (care_type_id)
WHERE diag_short_desc like 'Pneumonia unspecified'
---and ap.position=1
 "

#
# run the query against the database connection setup earlier
pneumonia_diag <- dbGetQuery( con, query_diag ) %>% 
  as_tibble() %>%
  mutate( diag_status = ifelse( position==1, 'Pdx','Adx'))
#
# disconnnect the database connection
did_disconnect <- dbDisconnect( con )


```

# Can we predict separation mode for pneumonia unspecified patients?

Given our 7517 pneumonia unspecified patients, can we predict their separation mode?  First, what does separation mode look like?



```{r pneumonia_unspecified_distribution, echo=TRUE, warnings=FALSE, messages=FALSE}

pneumonia_diag %>%
  ggplot( aes( sep_mode_desc, fill=diag_status)) +
  geom_bar( ) +
  coord_flip()
```

What is the frequency of each mode?
```{r frequency}

pneumonia_diag %>%
  count(  sep_mode_id, sep_mode_desc)

```
About 10% of patients with this diagnosis die.

## Data cleaning and manipulation

We create a new variable, `did_die`, which is 'Y' if they did die, and 'N' otherwise.  We also exclude some columns that are not useful for predicting (`admission_id`, `position`, `diag_code`, `diag_short_desc`), and also, exclude columns that would make the prediction too easy (`sep_mode_id` and `sep_mode_desc`).

```{r did_die}

pneumonia_diag_did_die <- 
  pneumonia_diag %>%
    mutate( did_die = ifelse( sep_mode_id=='D', 'Y', 'N')) %>%
    select( -admission_id, -position, -diag_code, -diag_short_desc, -sep_mode_id, -sep_mode_desc )

  pneumonia_diag_did_die %>%
    count( did_die )

```


# Machine learning

Can we use machine learning to determine the likelihood of death, given other factors?

First, we split the dataset into train and test data.  We will generate the machine learning model from the training set, and we then use the test set to see if our model is any good.

```{r machine_learn}

split_data <-  split_train_test(d=pneumonia_diag_did_die, outcome=did_die, percent_train=.8, seed=101001) 

summary(split_data)

```

## Training a prediction model

We train the model on the training subset, held in the `train` component of the `split_data` variable `split_data$train`. 

The outcome variable is the one we are trying to predict, in this case, `did_die`. We also set `tune=F` so that the process finishes more quickly, but if you have time, setting `tune=T` will give you a more accurate model.

```{r}

machine_learn( split_data$train, outcome=did_die, tune=F) %>% 
  { . } -> models

models

```

 `machine_learn` calculate *many* models, and has a contest to determine the best predictor.  The 3 models types are `Random Forest`, `eXtreme Gradient Boosting`, and `glmnet`.  The default model scoring criteria used is called `AUROC`, short for area under the ROC curve, and it shows that our model had a 84% success rate at predicting death, using the training set.  The best model was the `eXtreme Gradient Boosting` model.

## Evaluating the trained models
The final score is shown using the `evaluate` function

```{r}

evaluate(models, all_models=TRUE)
```
## Visualising a prediction model

There are various ways to visualise the results.  THe first is to look at what predictions would be made for the 'held back' training data.  `predict` does this, by adding a columm with the predicted `did_die` value, called `predicted_did_die`.  This contains the probability that this prediction will be `Y`. 

```{r}

predictions <- 
  predict(models, newdata=split_data$test, outcome_groups=T) 

predictions

```

We can plot the predictions.

```{r plot_predictions}

plot( predictions )


```

## How does the model work?

We first look and see which variables are important in the model.

```{r}


get_variable_importance(models) %>%
  plot()

```

Age and LOS are the most important variables.  Another way to explore the model is look at what happens to the prediction as you play around with the variables.  `explore` does this. By default, it explores the effect of changing the two most important variables in the model, in this case, `age_years` and `los`.


```{r}

explore(models) %>% 
  plot()

```

We can also explore what happens as we explore other combinations of variables, in this case, `age` and `care_type_desc`.

```{r}

explore(models, vary=c('age_years', 'care_type_desc')) %>% 
  plot()


```

### Exercises
1. Extract another dataset, for example, number of procedures performed, and if the patient had physiotherapy.  Does this selection of data improve the model?
2.  What is a plausible reason why a longer LOS leads to improved survival?
3.  If we had enough data, we could predict ICD codes.  What would the effect of this on the hospital workforce?


## Multiclass prediction
The following code selects out the top 3 seperation modes, and excludes the other seperation modes.  See if you can predict one of 3 seperation modes.  Does that improve accuracy?




```{r top3}


top3 <- 
  pneumonia_diag %>%
  count(  sep_mode_id, sep_mode_desc, sort=TRUE) %>%
  head(3)

pneumonia_diag_top3 <- 
  pneumonia_diag %>%
  inner_join( top3 ) %>%
  select( -position, -diag_code, -diag_short_desc, -sep_mode_desc, -n )


split_data <-  split_train_test(d=pneumonia_diag_top3 , outcome=sep_mode_id, percent_train=.8, seed=101001) 


machine_learn( split_data$train, admission_id, outcome=sep_mode_id, tune=F) %>% 
  { . } -> models

models

get_variable_importance(models) %>%
  plot()



```

